{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>Admission time</th>\n",
       "      <th>Discharge time</th>\n",
       "      <th>outcome</th>\n",
       "      <th>Hypersensitive c-reactive protein</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>eosinophils(%)</th>\n",
       "      <th>...</th>\n",
       "      <th>globulin</th>\n",
       "      <th>γ-glutamyl transpeptidase</th>\n",
       "      <th>serum sodium</th>\n",
       "      <th>glutamic-pyruvic transaminase</th>\n",
       "      <th>eGFR</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>Prothrombin time</th>\n",
       "      <th>Prothrombin activity</th>\n",
       "      <th>D-D dimer</th>\n",
       "      <th>International standard ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-30 22:12:47</td>\n",
       "      <td>2020-02-17 12:40:09</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>30.1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>142.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>88.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-04 21:39:03</td>\n",
       "      <td>2020-02-19 12:59:01</td>\n",
       "      <td>0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>33.2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>137.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>94.6</td>\n",
       "      <td>74.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-23 10:59:36</td>\n",
       "      <td>2020-02-08 17:52:31</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>29.8</td>\n",
       "      <td>53.0</td>\n",
       "      <td>143.2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>84.6</td>\n",
       "      <td>64.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-31 23:03:59</td>\n",
       "      <td>2020-02-18 12:59:12</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>31.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>144.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>74.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.260</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-01 20:59:54</td>\n",
       "      <td>2020-02-18 10:33:06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>143.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>122.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.420</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>357</td>\n",
       "      <td>371</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-04 11:51:01</td>\n",
       "      <td>2020-02-05 19:58:05</td>\n",
       "      <td>1</td>\n",
       "      <td>152.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>135.8</td>\n",
       "      <td>31.0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.570</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>358</td>\n",
       "      <td>372</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-05 17:52:06</td>\n",
       "      <td>2020-02-16 10:45:40</td>\n",
       "      <td>1</td>\n",
       "      <td>177.6</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>29.6</td>\n",
       "      <td>135.0</td>\n",
       "      <td>155.4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>364.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.110</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>359</td>\n",
       "      <td>373</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-12 03:07:48</td>\n",
       "      <td>2020-02-14 18:47:23</td>\n",
       "      <td>1</td>\n",
       "      <td>205.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>36.9</td>\n",
       "      <td>39.0</td>\n",
       "      <td>141.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>101.3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>77.0</td>\n",
       "      <td>6.246</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>360</td>\n",
       "      <td>374</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-03 22:16:30</td>\n",
       "      <td>2020-02-08 10:47:24</td>\n",
       "      <td>1</td>\n",
       "      <td>61.7</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.1</td>\n",
       "      <td>176.0</td>\n",
       "      <td>164.7</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>69.4</td>\n",
       "      <td>118.0</td>\n",
       "      <td>30.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.000</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>361</td>\n",
       "      <td>375</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-08 23:25:01</td>\n",
       "      <td>2020-02-19 01:31:58</td>\n",
       "      <td>1</td>\n",
       "      <td>267.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>139.3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>77.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.000</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  PATIENT_ID  age  gender       Admission time  \\\n",
       "0             1           1   73       1  2020-01-30 22:12:47   \n",
       "1             2           2   61       1  2020-02-04 21:39:03   \n",
       "2             3           3   70       2  2020-01-23 10:59:36   \n",
       "3             4           4   74       1  2020-01-31 23:03:59   \n",
       "4             5           5   29       2  2020-02-01 20:59:54   \n",
       "..          ...         ...  ...     ...                  ...   \n",
       "356         357         371   63       1  2020-02-04 11:51:01   \n",
       "357         358         372   79       1  2020-02-05 17:52:06   \n",
       "358         359         373   61       2  2020-02-12 03:07:48   \n",
       "359         360         374   33       1  2020-02-03 22:16:30   \n",
       "360         361         375   68       1  2020-02-08 23:25:01   \n",
       "\n",
       "          Discharge time  outcome  Hypersensitive c-reactive protein  \\\n",
       "0    2020-02-17 12:40:09        0                                2.6   \n",
       "1    2020-02-19 12:59:01        0                               27.4   \n",
       "2    2020-02-08 17:52:31        0                                3.6   \n",
       "3    2020-02-18 12:59:12        0                               14.5   \n",
       "4    2020-02-18 10:33:06        0                                0.8   \n",
       "..                   ...      ...                                ...   \n",
       "356  2020-02-05 19:58:05        1                              152.0   \n",
       "357  2020-02-16 10:45:40        1                              177.6   \n",
       "358  2020-02-14 18:47:23        1                              205.8   \n",
       "359  2020-02-08 10:47:24        1                               61.7   \n",
       "360  2020-02-19 01:31:58        1                              267.0   \n",
       "\n",
       "     hemoglobin  eosinophils(%)  ...  globulin  γ-glutamyl transpeptidase  \\\n",
       "0         131.0             1.7  ...      30.1                       41.0   \n",
       "1         149.0             0.1  ...      33.2                       50.0   \n",
       "2         126.0             0.1  ...      29.8                       53.0   \n",
       "3         103.0             2.5  ...      31.9                       14.0   \n",
       "4         130.0             3.0  ...      30.8                       21.0   \n",
       "..          ...             ...  ...       ...                        ...   \n",
       "356       143.0             0.0  ...      33.3                       27.0   \n",
       "357       102.0             0.2  ...      29.6                      135.0   \n",
       "358       100.0             0.1  ...      36.9                       39.0   \n",
       "359       121.0             0.0  ...      30.1                      176.0   \n",
       "360       155.0             0.0  ...      27.7                       33.0   \n",
       "\n",
       "     serum sodium  glutamic-pyruvic transaminase   eGFR  creatinine  \\\n",
       "0           142.7                           30.0   74.7        88.0   \n",
       "1           137.4                           22.0   94.6        74.0   \n",
       "2           143.2                           67.0   84.6        64.0   \n",
       "3           144.2                           26.0   74.2        88.0   \n",
       "4           143.6                           18.0  122.8        54.0   \n",
       "..            ...                            ...    ...         ...   \n",
       "356         135.8                           31.0   88.6        81.0   \n",
       "357         155.4                          121.0   12.9       364.0   \n",
       "358         141.6                            9.0  101.3        47.0   \n",
       "359         164.7                         1508.0   69.4       118.0   \n",
       "360         139.3                           17.0   88.6        77.0   \n",
       "\n",
       "     Prothrombin time  Prothrombin activity  D-D dimer  \\\n",
       "0                12.4                 115.0      0.920   \n",
       "1                12.3                 117.0      0.440   \n",
       "2                13.6                  94.0      0.980   \n",
       "3                16.3                  68.0      1.260   \n",
       "4                14.6                  83.0      0.420   \n",
       "..                ...                   ...        ...   \n",
       "356              14.4                  86.0      2.570   \n",
       "357              29.5                  27.0     11.110   \n",
       "358              14.9                  77.0      6.246   \n",
       "359              30.2                  26.0     21.000   \n",
       "360              17.9                  56.0     21.000   \n",
       "\n",
       "     International standard ratio  \n",
       "0                            0.92  \n",
       "1                            0.92  \n",
       "2                            1.04  \n",
       "3                            1.29  \n",
       "4                            1.13  \n",
       "..                            ...  \n",
       "356                          1.10  \n",
       "357                          2.76  \n",
       "358                          1.18  \n",
       "359                          2.90  \n",
       "360                          1.47  \n",
       "\n",
       "[361 rows x 59 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'../Datasets/summary_375_last.csv')\n",
    "df.shape\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                   0\n",
       "PATIENT_ID                                   0\n",
       "age                                          0\n",
       "gender                                       0\n",
       "Admission time                               0\n",
       "Discharge time                               0\n",
       "outcome                                      0\n",
       "Hypersensitive c-reactive protein            0\n",
       "hemoglobin                                   0\n",
       "eosinophils(%)                               0\n",
       "basophil(%)                                  0\n",
       "Platelet count                               0\n",
       "monocytes(%)                                 0\n",
       "Red blood cell distribution width            0\n",
       "neutrophils(%)                               0\n",
       "mean corpuscular volume                      0\n",
       "hematocrit                                   0\n",
       "White blood cell count                       0\n",
       "mean corpuscular hemoglobin concentration    0\n",
       "lymphocyte count                             0\n",
       "Red blood cell count                         0\n",
       "Eosinophil count                             0\n",
       "neutrophils count                            0\n",
       "Mean platelet volume                         0\n",
       "RBC distribution width SD                    0\n",
       "(%)lymphocyte                                0\n",
       "platelet large cell ratio                    0\n",
       "monocytes count                              0\n",
       "PLT distribution width                       0\n",
       "basophil count(#)                            0\n",
       "mean corpuscular hemoglobin                  0\n",
       "thrombocytocrit                              0\n",
       "glucose                                      0\n",
       "Serum chloride                               0\n",
       "Alkaline phosphatase                         0\n",
       "albumin                                      0\n",
       "Total bilirubin                              0\n",
       "indirect bilirubin                           0\n",
       "total protein                                0\n",
       "Urea                                         0\n",
       "Corrected calcium                            0\n",
       "Serum potassium                              0\n",
       "Direct bilirubin                             0\n",
       "Total cholesterol                            0\n",
       "aspartate aminotransferase                   0\n",
       "Uric acid                                    0\n",
       "HCO3-                                        0\n",
       "calcium                                      0\n",
       "Lactate dehydrogenase                        0\n",
       "globulin                                     0\n",
       "γ-glutamyl transpeptidase                    0\n",
       "serum sodium                                 0\n",
       "glutamic-pyruvic transaminase                0\n",
       "eGFR                                         0\n",
       "creatinine                                   0\n",
       "Prothrombin time                             0\n",
       "Prothrombin activity                         0\n",
       "D-D dimer                                    0\n",
       "International standard ratio                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting the NA values for each column \n",
    "count_nan = len(df) - df.count()\n",
    "count_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>Admission time</th>\n",
       "      <th>Discharge time</th>\n",
       "      <th>outcome</th>\n",
       "      <th>Hypersensitive c-reactive protein</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>eosinophils(%)</th>\n",
       "      <th>...</th>\n",
       "      <th>globulin</th>\n",
       "      <th>γ-glutamyl transpeptidase</th>\n",
       "      <th>serum sodium</th>\n",
       "      <th>glutamic-pyruvic transaminase</th>\n",
       "      <th>eGFR</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>Prothrombin time</th>\n",
       "      <th>Prothrombin activity</th>\n",
       "      <th>D-D dimer</th>\n",
       "      <th>International standard ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-30 22:12:47</td>\n",
       "      <td>2020-02-17 12:40:09</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>30.1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>142.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>88.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-04 21:39:03</td>\n",
       "      <td>2020-02-19 12:59:01</td>\n",
       "      <td>0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>33.2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>137.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>94.6</td>\n",
       "      <td>74.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-23 10:59:36</td>\n",
       "      <td>2020-02-08 17:52:31</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>29.8</td>\n",
       "      <td>53.0</td>\n",
       "      <td>143.2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>84.6</td>\n",
       "      <td>64.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-31 23:03:59</td>\n",
       "      <td>2020-02-18 12:59:12</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>31.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>144.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>74.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-01 20:59:54</td>\n",
       "      <td>2020-02-18 10:33:06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>143.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>122.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  PATIENT_ID  age  gender       Admission time  \\\n",
       "0           1           1   73       1  2020-01-30 22:12:47   \n",
       "1           2           2   61       1  2020-02-04 21:39:03   \n",
       "2           3           3   70       2  2020-01-23 10:59:36   \n",
       "3           4           4   74       1  2020-01-31 23:03:59   \n",
       "4           5           5   29       2  2020-02-01 20:59:54   \n",
       "\n",
       "        Discharge time  outcome  Hypersensitive c-reactive protein  \\\n",
       "0  2020-02-17 12:40:09        0                                2.6   \n",
       "1  2020-02-19 12:59:01        0                               27.4   \n",
       "2  2020-02-08 17:52:31        0                                3.6   \n",
       "3  2020-02-18 12:59:12        0                               14.5   \n",
       "4  2020-02-18 10:33:06        0                                0.8   \n",
       "\n",
       "   hemoglobin  eosinophils(%)  ...  globulin  γ-glutamyl transpeptidase  \\\n",
       "0       131.0             1.7  ...      30.1                       41.0   \n",
       "1       149.0             0.1  ...      33.2                       50.0   \n",
       "2       126.0             0.1  ...      29.8                       53.0   \n",
       "3       103.0             2.5  ...      31.9                       14.0   \n",
       "4       130.0             3.0  ...      30.8                       21.0   \n",
       "\n",
       "   serum sodium  glutamic-pyruvic transaminase   eGFR  creatinine  \\\n",
       "0         142.7                           30.0   74.7        88.0   \n",
       "1         137.4                           22.0   94.6        74.0   \n",
       "2         143.2                           67.0   84.6        64.0   \n",
       "3         144.2                           26.0   74.2        88.0   \n",
       "4         143.6                           18.0  122.8        54.0   \n",
       "\n",
       "   Prothrombin time  Prothrombin activity  D-D dimer  \\\n",
       "0              12.4                 115.0       0.92   \n",
       "1              12.3                 117.0       0.44   \n",
       "2              13.6                  94.0       0.98   \n",
       "3              16.3                  68.0       1.26   \n",
       "4              14.6                  83.0       0.42   \n",
       "\n",
       "   International standard ratio  \n",
       "0                          0.92  \n",
       "1                          0.92  \n",
       "2                          1.04  \n",
       "3                          1.29  \n",
       "4                          1.13  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop collumns that have more NA's than our thereshold\n",
    "df2 = df.dropna(thresh= len(df) - len(df)*0.06, axis=1 )\n",
    "df2.shape\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for col in df3.columns: print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>Admission time</th>\n",
       "      <th>Discharge time</th>\n",
       "      <th>outcome</th>\n",
       "      <th>Hypersensitive c-reactive protein</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>eosinophils(%)</th>\n",
       "      <th>...</th>\n",
       "      <th>globulin</th>\n",
       "      <th>γ-glutamyl transpeptidase</th>\n",
       "      <th>serum sodium</th>\n",
       "      <th>glutamic-pyruvic transaminase</th>\n",
       "      <th>eGFR</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>Prothrombin time</th>\n",
       "      <th>Prothrombin activity</th>\n",
       "      <th>D-D dimer</th>\n",
       "      <th>International standard ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-30 22:12:47</td>\n",
       "      <td>2020-02-17 12:40:09</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>30.1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>142.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>88.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-04 21:39:03</td>\n",
       "      <td>2020-02-19 12:59:01</td>\n",
       "      <td>0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>33.2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>137.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>94.6</td>\n",
       "      <td>74.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-23 10:59:36</td>\n",
       "      <td>2020-02-08 17:52:31</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>29.8</td>\n",
       "      <td>53.0</td>\n",
       "      <td>143.2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>84.6</td>\n",
       "      <td>64.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-31 23:03:59</td>\n",
       "      <td>2020-02-18 12:59:12</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>31.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>144.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>74.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.260</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-01 20:59:54</td>\n",
       "      <td>2020-02-18 10:33:06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>143.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>122.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.420</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>357</td>\n",
       "      <td>371</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-04 11:51:01</td>\n",
       "      <td>2020-02-05 19:58:05</td>\n",
       "      <td>1</td>\n",
       "      <td>152.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>135.8</td>\n",
       "      <td>31.0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.570</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>358</td>\n",
       "      <td>372</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-05 17:52:06</td>\n",
       "      <td>2020-02-16 10:45:40</td>\n",
       "      <td>1</td>\n",
       "      <td>177.6</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>29.6</td>\n",
       "      <td>135.0</td>\n",
       "      <td>155.4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>364.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.110</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>359</td>\n",
       "      <td>373</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-12 03:07:48</td>\n",
       "      <td>2020-02-14 18:47:23</td>\n",
       "      <td>1</td>\n",
       "      <td>205.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>36.9</td>\n",
       "      <td>39.0</td>\n",
       "      <td>141.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>101.3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>77.0</td>\n",
       "      <td>6.246</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>360</td>\n",
       "      <td>374</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-03 22:16:30</td>\n",
       "      <td>2020-02-08 10:47:24</td>\n",
       "      <td>1</td>\n",
       "      <td>61.7</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.1</td>\n",
       "      <td>176.0</td>\n",
       "      <td>164.7</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>69.4</td>\n",
       "      <td>118.0</td>\n",
       "      <td>30.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.000</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>361</td>\n",
       "      <td>375</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-08 23:25:01</td>\n",
       "      <td>2020-02-19 01:31:58</td>\n",
       "      <td>1</td>\n",
       "      <td>267.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>139.3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>77.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.000</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  PATIENT_ID  age  gender       Admission time  \\\n",
       "0             1           1   73       1  2020-01-30 22:12:47   \n",
       "1             2           2   61       1  2020-02-04 21:39:03   \n",
       "2             3           3   70       2  2020-01-23 10:59:36   \n",
       "3             4           4   74       1  2020-01-31 23:03:59   \n",
       "4             5           5   29       2  2020-02-01 20:59:54   \n",
       "..          ...         ...  ...     ...                  ...   \n",
       "356         357         371   63       1  2020-02-04 11:51:01   \n",
       "357         358         372   79       1  2020-02-05 17:52:06   \n",
       "358         359         373   61       2  2020-02-12 03:07:48   \n",
       "359         360         374   33       1  2020-02-03 22:16:30   \n",
       "360         361         375   68       1  2020-02-08 23:25:01   \n",
       "\n",
       "          Discharge time  outcome  Hypersensitive c-reactive protein  \\\n",
       "0    2020-02-17 12:40:09        0                                2.6   \n",
       "1    2020-02-19 12:59:01        0                               27.4   \n",
       "2    2020-02-08 17:52:31        0                                3.6   \n",
       "3    2020-02-18 12:59:12        0                               14.5   \n",
       "4    2020-02-18 10:33:06        0                                0.8   \n",
       "..                   ...      ...                                ...   \n",
       "356  2020-02-05 19:58:05        1                              152.0   \n",
       "357  2020-02-16 10:45:40        1                              177.6   \n",
       "358  2020-02-14 18:47:23        1                              205.8   \n",
       "359  2020-02-08 10:47:24        1                               61.7   \n",
       "360  2020-02-19 01:31:58        1                              267.0   \n",
       "\n",
       "     hemoglobin  eosinophils(%)  ...  globulin  γ-glutamyl transpeptidase  \\\n",
       "0         131.0             1.7  ...      30.1                       41.0   \n",
       "1         149.0             0.1  ...      33.2                       50.0   \n",
       "2         126.0             0.1  ...      29.8                       53.0   \n",
       "3         103.0             2.5  ...      31.9                       14.0   \n",
       "4         130.0             3.0  ...      30.8                       21.0   \n",
       "..          ...             ...  ...       ...                        ...   \n",
       "356       143.0             0.0  ...      33.3                       27.0   \n",
       "357       102.0             0.2  ...      29.6                      135.0   \n",
       "358       100.0             0.1  ...      36.9                       39.0   \n",
       "359       121.0             0.0  ...      30.1                      176.0   \n",
       "360       155.0             0.0  ...      27.7                       33.0   \n",
       "\n",
       "     serum sodium  glutamic-pyruvic transaminase   eGFR  creatinine  \\\n",
       "0           142.7                           30.0   74.7        88.0   \n",
       "1           137.4                           22.0   94.6        74.0   \n",
       "2           143.2                           67.0   84.6        64.0   \n",
       "3           144.2                           26.0   74.2        88.0   \n",
       "4           143.6                           18.0  122.8        54.0   \n",
       "..            ...                            ...    ...         ...   \n",
       "356         135.8                           31.0   88.6        81.0   \n",
       "357         155.4                          121.0   12.9       364.0   \n",
       "358         141.6                            9.0  101.3        47.0   \n",
       "359         164.7                         1508.0   69.4       118.0   \n",
       "360         139.3                           17.0   88.6        77.0   \n",
       "\n",
       "     Prothrombin time  Prothrombin activity  D-D dimer  \\\n",
       "0                12.4                 115.0      0.920   \n",
       "1                12.3                 117.0      0.440   \n",
       "2                13.6                  94.0      0.980   \n",
       "3                16.3                  68.0      1.260   \n",
       "4                14.6                  83.0      0.420   \n",
       "..                ...                   ...        ...   \n",
       "356              14.4                  86.0      2.570   \n",
       "357              29.5                  27.0     11.110   \n",
       "358              14.9                  77.0      6.246   \n",
       "359              30.2                  26.0     21.000   \n",
       "360              17.9                  56.0     21.000   \n",
       "\n",
       "     International standard ratio  \n",
       "0                            0.92  \n",
       "1                            0.92  \n",
       "2                            1.04  \n",
       "3                            1.29  \n",
       "4                            1.13  \n",
       "..                            ...  \n",
       "356                          1.10  \n",
       "357                          2.76  \n",
       "358                          1.18  \n",
       "359                          2.90  \n",
       "360                          1.47  \n",
       "\n",
       "[361 rows x 59 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#col_means = df3.mean()\n",
    "#col_means\n",
    "#filling na values with the column mean \n",
    "df3 = df2.fillna(df2.mean())\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in df3.columns: \n",
    "#    if col == 'Lactate dehydrogenase' : \n",
    "#        print (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>outcome</th>\n",
       "      <th>Hypersensitive c-reactive protein</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>eosinophils(%)</th>\n",
       "      <th>basophil(%)</th>\n",
       "      <th>Platelet count</th>\n",
       "      <th>monocytes(%)</th>\n",
       "      <th>...</th>\n",
       "      <th>globulin</th>\n",
       "      <th>γ-glutamyl transpeptidase</th>\n",
       "      <th>serum sodium</th>\n",
       "      <th>glutamic-pyruvic transaminase</th>\n",
       "      <th>eGFR</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>Prothrombin time</th>\n",
       "      <th>Prothrombin activity</th>\n",
       "      <th>D-D dimer</th>\n",
       "      <th>International standard ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>141.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>...</td>\n",
       "      <td>30.1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>142.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>88.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>283.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>33.2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>137.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>94.6</td>\n",
       "      <td>74.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>238.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>...</td>\n",
       "      <td>29.8</td>\n",
       "      <td>53.0</td>\n",
       "      <td>143.2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>84.6</td>\n",
       "      <td>64.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>300.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>...</td>\n",
       "      <td>31.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>144.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>74.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.260</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>356.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>...</td>\n",
       "      <td>30.8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>143.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>122.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.420</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>371</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>152.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>33.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>135.8</td>\n",
       "      <td>31.0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.570</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>372</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>177.6</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>29.6</td>\n",
       "      <td>135.0</td>\n",
       "      <td>155.4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>364.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.110</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>373</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>205.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>136.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>36.9</td>\n",
       "      <td>39.0</td>\n",
       "      <td>141.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>101.3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>77.0</td>\n",
       "      <td>6.246</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>374</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61.7</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>30.1</td>\n",
       "      <td>176.0</td>\n",
       "      <td>164.7</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>69.4</td>\n",
       "      <td>118.0</td>\n",
       "      <td>30.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.000</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>375</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>267.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>139.3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>77.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.000</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PATIENT_ID  age  gender  outcome  Hypersensitive c-reactive protein  \\\n",
       "0             1   73       1        0                                2.6   \n",
       "1             2   61       1        0                               27.4   \n",
       "2             3   70       2        0                                3.6   \n",
       "3             4   74       1        0                               14.5   \n",
       "4             5   29       2        0                                0.8   \n",
       "..          ...  ...     ...      ...                                ...   \n",
       "356         371   63       1        1                              152.0   \n",
       "357         372   79       1        1                              177.6   \n",
       "358         373   61       2        1                              205.8   \n",
       "359         374   33       1        1                               61.7   \n",
       "360         375   68       1        1                              267.0   \n",
       "\n",
       "     hemoglobin  eosinophils(%)  basophil(%)  Platelet count  monocytes(%)  \\\n",
       "0         131.0             1.7          0.2           141.0           7.9   \n",
       "1         149.0             0.1          0.3           283.0           5.7   \n",
       "2         126.0             0.1          0.1           238.0           6.1   \n",
       "3         103.0             2.5          0.3           300.0           8.6   \n",
       "4         130.0             3.0          0.5           356.0           7.4   \n",
       "..          ...             ...          ...             ...           ...   \n",
       "356       143.0             0.0          0.0           149.0           5.5   \n",
       "357       102.0             0.2          0.2            48.0           0.9   \n",
       "358       100.0             0.1          0.1           136.0           4.5   \n",
       "359       121.0             0.0          0.3            54.0           2.9   \n",
       "360       155.0             0.0          0.6            17.0           1.0   \n",
       "\n",
       "     ...  globulin  γ-glutamyl transpeptidase  serum sodium  \\\n",
       "0    ...      30.1                       41.0         142.7   \n",
       "1    ...      33.2                       50.0         137.4   \n",
       "2    ...      29.8                       53.0         143.2   \n",
       "3    ...      31.9                       14.0         144.2   \n",
       "4    ...      30.8                       21.0         143.6   \n",
       "..   ...       ...                        ...           ...   \n",
       "356  ...      33.3                       27.0         135.8   \n",
       "357  ...      29.6                      135.0         155.4   \n",
       "358  ...      36.9                       39.0         141.6   \n",
       "359  ...      30.1                      176.0         164.7   \n",
       "360  ...      27.7                       33.0         139.3   \n",
       "\n",
       "     glutamic-pyruvic transaminase   eGFR  creatinine  Prothrombin time  \\\n",
       "0                             30.0   74.7        88.0              12.4   \n",
       "1                             22.0   94.6        74.0              12.3   \n",
       "2                             67.0   84.6        64.0              13.6   \n",
       "3                             26.0   74.2        88.0              16.3   \n",
       "4                             18.0  122.8        54.0              14.6   \n",
       "..                             ...    ...         ...               ...   \n",
       "356                           31.0   88.6        81.0              14.4   \n",
       "357                          121.0   12.9       364.0              29.5   \n",
       "358                            9.0  101.3        47.0              14.9   \n",
       "359                         1508.0   69.4       118.0              30.2   \n",
       "360                           17.0   88.6        77.0              17.9   \n",
       "\n",
       "     Prothrombin activity  D-D dimer  International standard ratio  \n",
       "0                   115.0      0.920                          0.92  \n",
       "1                   117.0      0.440                          0.92  \n",
       "2                    94.0      0.980                          1.04  \n",
       "3                    68.0      1.260                          1.29  \n",
       "4                    83.0      0.420                          1.13  \n",
       "..                    ...        ...                           ...  \n",
       "356                  86.0      2.570                          1.10  \n",
       "357                  27.0     11.110                          2.76  \n",
       "358                  77.0      6.246                          1.18  \n",
       "359                  26.0     21.000                          2.90  \n",
       "360                  56.0     21.000                          1.47  \n",
       "\n",
       "[361 rows x 56 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping unusefull atributes \n",
    "df_final  = df3.drop([\"Unnamed: 0\", 'Admission time','Discharge time'], axis=1)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>outcome</th>\n",
       "      <th>Hypersensitive c-reactive protein</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>eosinophils(%)</th>\n",
       "      <th>basophil(%)</th>\n",
       "      <th>Platelet count</th>\n",
       "      <th>monocytes(%)</th>\n",
       "      <th>...</th>\n",
       "      <th>globulin</th>\n",
       "      <th>γ-glutamyl transpeptidase</th>\n",
       "      <th>serum sodium</th>\n",
       "      <th>glutamic-pyruvic transaminase</th>\n",
       "      <th>eGFR</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>Prothrombin time</th>\n",
       "      <th>Prothrombin activity</th>\n",
       "      <th>D-D dimer</th>\n",
       "      <th>International standard ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>141.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>...</td>\n",
       "      <td>30.1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>142.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>88.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>283.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>33.2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>137.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>94.6</td>\n",
       "      <td>74.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>238.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>...</td>\n",
       "      <td>29.8</td>\n",
       "      <td>53.0</td>\n",
       "      <td>143.2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>84.6</td>\n",
       "      <td>64.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>300.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>...</td>\n",
       "      <td>31.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>144.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>74.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.260</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>356.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>...</td>\n",
       "      <td>30.8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>143.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>122.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.420</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>371</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>152.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>33.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>135.8</td>\n",
       "      <td>31.0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.570</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>372</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>177.6</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>29.6</td>\n",
       "      <td>135.0</td>\n",
       "      <td>155.4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>364.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.110</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>373</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>205.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>136.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>36.9</td>\n",
       "      <td>39.0</td>\n",
       "      <td>141.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>101.3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>77.0</td>\n",
       "      <td>6.246</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>374</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61.7</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>30.1</td>\n",
       "      <td>176.0</td>\n",
       "      <td>164.7</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>69.4</td>\n",
       "      <td>118.0</td>\n",
       "      <td>30.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.000</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>375</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>267.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>139.3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>77.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.000</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PATIENT_ID  age  gender  outcome  Hypersensitive c-reactive protein  \\\n",
       "0             1   73       1        0                                2.6   \n",
       "1             2   61       1        0                               27.4   \n",
       "2             3   70       2        0                                3.6   \n",
       "3             4   74       1        0                               14.5   \n",
       "4             5   29       2        0                                0.8   \n",
       "..          ...  ...     ...      ...                                ...   \n",
       "356         371   63       1        1                              152.0   \n",
       "357         372   79       1        1                              177.6   \n",
       "358         373   61       2        1                              205.8   \n",
       "359         374   33       1        1                               61.7   \n",
       "360         375   68       1        1                              267.0   \n",
       "\n",
       "     hemoglobin  eosinophils(%)  basophil(%)  Platelet count  monocytes(%)  \\\n",
       "0         131.0             1.7          0.2           141.0           7.9   \n",
       "1         149.0             0.1          0.3           283.0           5.7   \n",
       "2         126.0             0.1          0.1           238.0           6.1   \n",
       "3         103.0             2.5          0.3           300.0           8.6   \n",
       "4         130.0             3.0          0.5           356.0           7.4   \n",
       "..          ...             ...          ...             ...           ...   \n",
       "356       143.0             0.0          0.0           149.0           5.5   \n",
       "357       102.0             0.2          0.2            48.0           0.9   \n",
       "358       100.0             0.1          0.1           136.0           4.5   \n",
       "359       121.0             0.0          0.3            54.0           2.9   \n",
       "360       155.0             0.0          0.6            17.0           1.0   \n",
       "\n",
       "     ...  globulin  γ-glutamyl transpeptidase  serum sodium  \\\n",
       "0    ...      30.1                       41.0         142.7   \n",
       "1    ...      33.2                       50.0         137.4   \n",
       "2    ...      29.8                       53.0         143.2   \n",
       "3    ...      31.9                       14.0         144.2   \n",
       "4    ...      30.8                       21.0         143.6   \n",
       "..   ...       ...                        ...           ...   \n",
       "356  ...      33.3                       27.0         135.8   \n",
       "357  ...      29.6                      135.0         155.4   \n",
       "358  ...      36.9                       39.0         141.6   \n",
       "359  ...      30.1                      176.0         164.7   \n",
       "360  ...      27.7                       33.0         139.3   \n",
       "\n",
       "     glutamic-pyruvic transaminase   eGFR  creatinine  Prothrombin time  \\\n",
       "0                             30.0   74.7        88.0              12.4   \n",
       "1                             22.0   94.6        74.0              12.3   \n",
       "2                             67.0   84.6        64.0              13.6   \n",
       "3                             26.0   74.2        88.0              16.3   \n",
       "4                             18.0  122.8        54.0              14.6   \n",
       "..                             ...    ...         ...               ...   \n",
       "356                           31.0   88.6        81.0              14.4   \n",
       "357                          121.0   12.9       364.0              29.5   \n",
       "358                            9.0  101.3        47.0              14.9   \n",
       "359                         1508.0   69.4       118.0              30.2   \n",
       "360                           17.0   88.6        77.0              17.9   \n",
       "\n",
       "     Prothrombin activity  D-D dimer  International standard ratio  \n",
       "0                   115.0      0.920                          0.92  \n",
       "1                   117.0      0.440                          0.92  \n",
       "2                    94.0      0.980                          1.04  \n",
       "3                    68.0      1.260                          1.29  \n",
       "4                    83.0      0.420                          1.13  \n",
       "..                    ...        ...                           ...  \n",
       "356                  86.0      2.570                          1.10  \n",
       "357                  27.0     11.110                          2.76  \n",
       "358                  77.0      6.246                          1.18  \n",
       "359                  26.0     21.000                          2.90  \n",
       "360                  56.0     21.000                          1.47  \n",
       "\n",
       "[361 rows x 56 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(361, 54)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df4 = df3.dropna(axis=1, how='any')\n",
    "#df4\n",
    "#constucting X and y \n",
    "X = df_final.drop([\"PATIENT_ID\",'outcome'], axis=1)\n",
    "y= df_final['outcome']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>Hypersensitive c-reactive protein</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>eosinophils(%)</th>\n",
       "      <th>basophil(%)</th>\n",
       "      <th>Platelet count</th>\n",
       "      <th>monocytes(%)</th>\n",
       "      <th>Red blood cell distribution width</th>\n",
       "      <th>neutrophils(%)</th>\n",
       "      <th>...</th>\n",
       "      <th>globulin</th>\n",
       "      <th>γ-glutamyl transpeptidase</th>\n",
       "      <th>serum sodium</th>\n",
       "      <th>glutamic-pyruvic transaminase</th>\n",
       "      <th>eGFR</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>Prothrombin time</th>\n",
       "      <th>Prothrombin activity</th>\n",
       "      <th>D-D dimer</th>\n",
       "      <th>International standard ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>141.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>11.900</td>\n",
       "      <td>64.3</td>\n",
       "      <td>...</td>\n",
       "      <td>30.1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>142.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>88.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>27.4</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>283.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>13.100</td>\n",
       "      <td>84.7</td>\n",
       "      <td>...</td>\n",
       "      <td>33.2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>137.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>94.6</td>\n",
       "      <td>74.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>238.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>12.600</td>\n",
       "      <td>66.4</td>\n",
       "      <td>...</td>\n",
       "      <td>29.8</td>\n",
       "      <td>53.0</td>\n",
       "      <td>143.2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>84.6</td>\n",
       "      <td>64.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>300.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>14.300</td>\n",
       "      <td>72.1</td>\n",
       "      <td>...</td>\n",
       "      <td>31.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>144.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>74.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.260</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>356.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>12.400</td>\n",
       "      <td>65.5</td>\n",
       "      <td>...</td>\n",
       "      <td>30.8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>143.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>122.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.420</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>152.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>11.900</td>\n",
       "      <td>79.5</td>\n",
       "      <td>...</td>\n",
       "      <td>33.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>135.8</td>\n",
       "      <td>31.0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.570</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>177.6</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>15.500</td>\n",
       "      <td>98.1</td>\n",
       "      <td>...</td>\n",
       "      <td>29.6</td>\n",
       "      <td>135.0</td>\n",
       "      <td>155.4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>364.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.110</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>205.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>136.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13.900</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.9</td>\n",
       "      <td>39.0</td>\n",
       "      <td>141.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>101.3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>77.0</td>\n",
       "      <td>6.246</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>61.7</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>13.215</td>\n",
       "      <td>94.5</td>\n",
       "      <td>...</td>\n",
       "      <td>30.1</td>\n",
       "      <td>176.0</td>\n",
       "      <td>164.7</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>69.4</td>\n",
       "      <td>118.0</td>\n",
       "      <td>30.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.000</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>267.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.100</td>\n",
       "      <td>91.7</td>\n",
       "      <td>...</td>\n",
       "      <td>27.7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>139.3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>77.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.000</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  gender  Hypersensitive c-reactive protein  hemoglobin  \\\n",
       "0     73       1                                2.6       131.0   \n",
       "1     61       1                               27.4       149.0   \n",
       "2     70       2                                3.6       126.0   \n",
       "3     74       1                               14.5       103.0   \n",
       "4     29       2                                0.8       130.0   \n",
       "..   ...     ...                                ...         ...   \n",
       "356   63       1                              152.0       143.0   \n",
       "357   79       1                              177.6       102.0   \n",
       "358   61       2                              205.8       100.0   \n",
       "359   33       1                               61.7       121.0   \n",
       "360   68       1                              267.0       155.0   \n",
       "\n",
       "     eosinophils(%)  basophil(%)  Platelet count  monocytes(%)  \\\n",
       "0               1.7          0.2           141.0           7.9   \n",
       "1               0.1          0.3           283.0           5.7   \n",
       "2               0.1          0.1           238.0           6.1   \n",
       "3               2.5          0.3           300.0           8.6   \n",
       "4               3.0          0.5           356.0           7.4   \n",
       "..              ...          ...             ...           ...   \n",
       "356             0.0          0.0           149.0           5.5   \n",
       "357             0.2          0.2            48.0           0.9   \n",
       "358             0.1          0.1           136.0           4.5   \n",
       "359             0.0          0.3            54.0           2.9   \n",
       "360             0.0          0.6            17.0           1.0   \n",
       "\n",
       "     Red blood cell distribution width  neutrophils(%)  ...  globulin  \\\n",
       "0                               11.900            64.3  ...      30.1   \n",
       "1                               13.100            84.7  ...      33.2   \n",
       "2                               12.600            66.4  ...      29.8   \n",
       "3                               14.300            72.1  ...      31.9   \n",
       "4                               12.400            65.5  ...      30.8   \n",
       "..                                 ...             ...  ...       ...   \n",
       "356                             11.900            79.5  ...      33.3   \n",
       "357                             15.500            98.1  ...      29.6   \n",
       "358                             13.900            89.0  ...      36.9   \n",
       "359                             13.215            94.5  ...      30.1   \n",
       "360                             13.100            91.7  ...      27.7   \n",
       "\n",
       "     γ-glutamyl transpeptidase  serum sodium  glutamic-pyruvic transaminase  \\\n",
       "0                         41.0         142.7                           30.0   \n",
       "1                         50.0         137.4                           22.0   \n",
       "2                         53.0         143.2                           67.0   \n",
       "3                         14.0         144.2                           26.0   \n",
       "4                         21.0         143.6                           18.0   \n",
       "..                         ...           ...                            ...   \n",
       "356                       27.0         135.8                           31.0   \n",
       "357                      135.0         155.4                          121.0   \n",
       "358                       39.0         141.6                            9.0   \n",
       "359                      176.0         164.7                         1508.0   \n",
       "360                       33.0         139.3                           17.0   \n",
       "\n",
       "      eGFR  creatinine  Prothrombin time  Prothrombin activity  D-D dimer  \\\n",
       "0     74.7        88.0              12.4                 115.0      0.920   \n",
       "1     94.6        74.0              12.3                 117.0      0.440   \n",
       "2     84.6        64.0              13.6                  94.0      0.980   \n",
       "3     74.2        88.0              16.3                  68.0      1.260   \n",
       "4    122.8        54.0              14.6                  83.0      0.420   \n",
       "..     ...         ...               ...                   ...        ...   \n",
       "356   88.6        81.0              14.4                  86.0      2.570   \n",
       "357   12.9       364.0              29.5                  27.0     11.110   \n",
       "358  101.3        47.0              14.9                  77.0      6.246   \n",
       "359   69.4       118.0              30.2                  26.0     21.000   \n",
       "360   88.6        77.0              17.9                  56.0     21.000   \n",
       "\n",
       "     International standard ratio  \n",
       "0                            0.92  \n",
       "1                            0.92  \n",
       "2                            1.04  \n",
       "3                            1.29  \n",
       "4                            1.13  \n",
       "..                            ...  \n",
       "356                          1.10  \n",
       "357                          2.76  \n",
       "358                          1.18  \n",
       "359                          2.90  \n",
       "360                          1.47  \n",
       "\n",
       "[361 rows x 54 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98        63\n",
      "           1       0.96      0.98      0.97        46\n",
      "\n",
      "    accuracy                           0.97       109\n",
      "   macro avg       0.97      0.97      0.97       109\n",
      "weighted avg       0.97      0.97      0.97       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#splitting the dataset to train and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size=0.3, random_state=0)\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=10000, random_state=0)\n",
    "logreg = logreg.fit(X_train, y_train)\n",
    "\n",
    "#making a prediction\n",
    "y_pred= logreg.predict(X_test)\n",
    "\n",
    "#print (clf.predict_proba(y_test))\n",
    "\n",
    "#clf.score(X_train, y_train)\n",
    "#?#how to do regression in non numerical values\n",
    "\n",
    "#print('Test accuracy of the model:' , logreg.score(X_test, y_pred), \"\\n\")\n",
    "\n",
    "print('Classification report:',\"\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation accuracy scores: [0.95890411 0.94444444 0.97222222 0.95833333 0.90277778]\n",
      "Mean of Cross Validation scores: 0.9473363774733639\n"
     ]
    }
   ],
   "source": [
    "#implementing 5-fold cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(logreg, X, y, cv=5, scoring= 'accuracy')\n",
    "print('Cross Validation accuracy scores:', scores)\n",
    "print('Mean of Cross Validation scores:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98        63\n",
      "           1       0.96      0.98      0.97        46\n",
      "\n",
      "    accuracy                           0.97       109\n",
      "   macro avg       0.97      0.97      0.97       109\n",
      "weighted avg       0.97      0.97      0.97       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#modify thresshold based on the optimal fundings of the ROC curve  \n",
    "import numpy as np\n",
    "\n",
    "THRESHOLD = 0.5\n",
    "preds = np.where(logreg.predict(X_test) > THRESHOLD, 1, 0)\n",
    "\n",
    "print('Classification report:',\"\\n\", classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#modify thresshold based on the optimal fundings of the ROC curve  \n",
    "proba = logreg.predict_proba(X_test)[:,1]\n",
    "#print (proba.size)\n",
    "\n",
    "y_pred_thres2= [None for _ in range(proba.size)]\n",
    "\n",
    "for i in range(75):\n",
    "    if proba[i] >= 0.452030 : \n",
    "        y_pred_thres2[i]=1\n",
    "        #y_pred2[i].append(y_pred2)\n",
    "    else:\n",
    "        y_pred_thres2[i]=0\n",
    "        #y_pred2.append(y_pred2)\n",
    "\n",
    "y_pred_thres2\n",
    "\n",
    "print(classification_report(y_test, y_pred_thres2))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal threshold via ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "proba = logreg.predict_proba(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, proba)\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_ls = []\n",
    "for thres in thresholds:\n",
    "    y_pred = np.where(proba>thres,1,0)\n",
    "    accuracy_ls.append(accuracy_score(y_test, y_pred, normalize=True))\n",
    "    \n",
    "accuracy_ls = pd.concat([pd.Series(thresholds), pd.Series(accuracy_ls)],\n",
    "                        axis=1)\n",
    "accuracy_ls.columns = ['thresholds', 'accuracy']\n",
    "accuracy_ls.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "accuracy_ls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(num=1, figsize=(3, 4), dpi=300, facecolor='w', edgecolor='k')\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "figure = plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_thres2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9724770642201835\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98        63\n",
      "           1       0.98      0.96      0.97        46\n",
      "\n",
      "    accuracy                           0.97       109\n",
      "   macro avg       0.97      0.97      0.97       109\n",
      "weighted avg       0.97      0.97      0.97       109\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=4,random_state=0) #max_depth=7,\n",
    "\n",
    "clf = clf.fit(X_train ,y_train)\n",
    "\n",
    "#print ('train accuracy:', clf.score(X_train, y_train))\n",
    "print ('Test accuracy:', clf.score(X_test, y_test))\n",
    "\n",
    "y_pred_tree = clf.predict(X_test)\n",
    "\n",
    "print('Classification report:',\"\\n\", classification_report(y_test, y_pred_tree))\n",
    "\n",
    "tree.plot_tree(clf, filled = True, fontsize = 7) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x [32, 3,38 , 34, 18, 39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hypersensitive c-reactive protein'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation accuracy scores: [0.94520548 0.93055556 0.98611111 0.95833333 0.875     ]\n",
      "Mean of Cross Validation scores: 0.939041095890411\n"
     ]
    }
   ],
   "source": [
    "#implementing 5-fold cross validation for the decission tree\n",
    "scores = cross_val_score(clf, X, y, cv=5, scoring= 'accuracy')\n",
    "print('Cross Validation accuracy scores:', scores)\n",
    "print('Mean of Cross Validation scores:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.963302752293578 \n",
      "\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        63\n",
      "           1       0.96      0.96      0.96        46\n",
      "\n",
      "    accuracy                           0.96       109\n",
      "   macro avg       0.96      0.96      0.96       109\n",
      "weighted avg       0.96      0.96      0.96       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost = AdaBoostClassifier(random_state=0)\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "adaboost.predict(X_test)\n",
    "\n",
    "print ('Test accuracy:', adaboost.score(X_test, y_test),\"\\n\")\n",
    "\n",
    "y_pred_adaboost = adaboost.predict(X_test)\n",
    "\n",
    "print('Classification report:',\"\\n\", classification_report(y_test, y_pred_adaboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation accuracy scores: [0.95890411 0.95833333 0.94444444 0.97222222 0.93055556]\n",
      "Mean of Cross Validation scores: 0.9528919330289194\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(adaboost, X, y, cv=5, scoring= 'accuracy')\n",
    "print('Cross Validation accuracy scores:', scores)\n",
    "print('Mean of Cross Validation scores:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.981651376146789\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        63\n",
      "           1       0.98      0.98      0.98        46\n",
      "\n",
      "    accuracy                           0.98       109\n",
      "   macro avg       0.98      0.98      0.98       109\n",
      "weighted avg       0.98      0.98      0.98       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#svm_model = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "svm_model =svm.SVC(kernel='rbf',  C=100)\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_SVM = svm_model.predict(X_test)\n",
    "\n",
    "print ('Test accuracy:', svm_model.score(X_test, y_test))\n",
    "print('Classification report:',\"\\n\", classification_report(y_test, y_pred_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation accuracy scores: [0.98630137 0.90277778 0.97222222 0.98611111 0.93055556]\n",
      "Mean of Cross Validation scores: 0.955593607305936\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svm_model, X, y, cv=5, scoring= 'accuracy')\n",
    "print('Cross Validation accuracy scores:', scores)\n",
    "print('Mean of Cross Validation scores:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================= NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "classifier = Sequential() # Initialising the ANN\n",
    "\n",
    "classifier.add(Dense(units = 20, activation = 'relu', input_dim = 54))\n",
    "classifier.add(Dense(units = 10, activation = 'relu'))\n",
    "classifier.add(Dense(units = 7, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 1s 479us/step - loss: 4.5495\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 1.6841\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1.0797\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.5510\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.6450\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.5511\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.5094\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 596us/step - loss: 0.3523\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.3198\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.2603\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.2917\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.2360\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.2042\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.2416\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.2472\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.2145\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.1750\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0889\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.1149\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.1862\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0894\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.1492\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0868\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0836\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.1567\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.1675\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0495\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.1614\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0710\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0476\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0709\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.1367\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.1285\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0907\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0991\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0951\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0946\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0911\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.1038\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0973\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0770\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0847\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0802\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.1347\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0895\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0913\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0423\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0760\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0690\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0519\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0740\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0357\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0492\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0540\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0728\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.106 - 0s 519us/step - loss: 0.1098\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.1033\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.1183\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0936\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0731\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0445\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0516\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0939\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0459\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.1108\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0781\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.1174\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0686\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0605\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0983\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0689\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0498\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0770\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.0482\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0326\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0359\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0603\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0372\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0581\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0411\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0538\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0817\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0849\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0340\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.0972\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0232\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 756us/step - loss: 0.0884\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0874\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 758us/step - loss: 0.0510\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 599us/step - loss: 0.0417\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0575\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 459us/step - loss: 0.0361\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0380\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0675\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0443\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0696\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0879\n",
      "Epoch 98/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 499us/step - loss: 0.0458\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0363\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0216\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0713\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0271\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0247\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0713\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s 529us/step - loss: 0.0213\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0553\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0262\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0300\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0328\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0253\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 0s 499us/step - loss: 0.0517\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0365\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0183\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s 758us/step - loss: 0.0884\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0277\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0212\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s 499us/step - loss: 0.0392\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0198\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0417\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0601\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0467\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0185\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0297\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0351\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0419\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0502\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0580\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0166\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0157\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0348\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0932\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0329\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0827\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0214\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0235\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0195\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0402\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0371\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0250\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0318\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0176\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0564\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0223\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0880\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0321\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0206\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0301\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0331\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0199\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0371\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0258\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0229\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0281\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0275\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0264\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0294\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0399\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0215\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 0s 580us/step - loss: 0.0320\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 0s 998us/step - loss: 0.0546\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0493\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0181\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0186\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0226\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0223\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0250\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0236\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0443\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0293\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0216\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0398\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0217\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0991\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0197\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0386\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.0268\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.0249\n",
      "Epoch 178/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0290\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0107\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0287\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0206\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0178\n",
      "Epoch 183/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0514\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0677\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0172\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0366\n",
      "Epoch 187/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0690\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0171\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0249\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0391\n",
      "Epoch 191/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0233\n",
      "Epoch 192/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0292\n",
      "Epoch 193/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0326\n",
      "Epoch 194/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 479us/step - loss: 0.0395\n",
      "Epoch 195/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.1112\n",
      "Epoch 196/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0162\n",
      "Epoch 197/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0233\n",
      "Epoch 198/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0311\n",
      "Epoch 199/1000\n",
      "26/26 [==============================] - 0s 512us/step - loss: 0.0256\n",
      "Epoch 200/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0128\n",
      "Epoch 201/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0556\n",
      "Epoch 202/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0198\n",
      "Epoch 203/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0486\n",
      "Epoch 204/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0240\n",
      "Epoch 205/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0112\n",
      "Epoch 206/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0293\n",
      "Epoch 207/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0200\n",
      "Epoch 208/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0360\n",
      "Epoch 209/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0123\n",
      "Epoch 210/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0277\n",
      "Epoch 211/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0126\n",
      "Epoch 212/1000\n",
      "26/26 [==============================] - 0s 499us/step - loss: 0.0126\n",
      "Epoch 213/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0304\n",
      "Epoch 214/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0160\n",
      "Epoch 215/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0725\n",
      "Epoch 216/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0168\n",
      "Epoch 217/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.3131\n",
      "Epoch 218/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0347\n",
      "Epoch 219/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0175\n",
      "Epoch 220/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0244\n",
      "Epoch 221/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0380\n",
      "Epoch 222/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0182\n",
      "Epoch 223/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0270\n",
      "Epoch 224/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0556\n",
      "Epoch 225/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0136\n",
      "Epoch 226/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0184\n",
      "Epoch 227/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0362\n",
      "Epoch 228/1000\n",
      "26/26 [==============================] - 0s 639us/step - loss: 0.0247\n",
      "Epoch 229/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0173\n",
      "Epoch 230/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0210\n",
      "Epoch 231/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0277\n",
      "Epoch 232/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0192\n",
      "Epoch 233/1000\n",
      "26/26 [==============================] - 0s 659us/step - loss: 0.0180\n",
      "Epoch 234/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0158\n",
      "Epoch 235/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0203\n",
      "Epoch 236/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0161\n",
      "Epoch 237/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0419\n",
      "Epoch 238/1000\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.0220\n",
      "Epoch 239/1000\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.0167\n",
      "Epoch 240/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0436\n",
      "Epoch 241/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0126\n",
      "Epoch 242/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0140\n",
      "Epoch 243/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0256\n",
      "Epoch 244/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0182\n",
      "Epoch 245/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0094\n",
      "Epoch 246/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0148\n",
      "Epoch 247/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0431\n",
      "Epoch 248/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0492\n",
      "Epoch 249/1000\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.0118\n",
      "Epoch 250/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0203\n",
      "Epoch 251/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0271\n",
      "Epoch 252/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0095\n",
      "Epoch 253/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0190\n",
      "Epoch 254/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0153\n",
      "Epoch 255/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0108\n",
      "Epoch 256/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0400\n",
      "Epoch 257/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0144\n",
      "Epoch 258/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0138\n",
      "Epoch 259/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0245\n",
      "Epoch 260/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0208\n",
      "Epoch 261/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0203\n",
      "Epoch 262/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0216\n",
      "Epoch 263/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.1694\n",
      "Epoch 264/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0153\n",
      "Epoch 265/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0155\n",
      "Epoch 266/1000\n",
      "26/26 [==============================] - 0s 557us/step - loss: 0.0254\n",
      "Epoch 267/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0238\n",
      "Epoch 268/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.1169\n",
      "Epoch 269/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0195\n",
      "Epoch 270/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0162\n",
      "Epoch 271/1000\n",
      "26/26 [==============================] - 0s 560us/step - loss: 0.0228\n",
      "Epoch 272/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0079\n",
      "Epoch 273/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0115\n",
      "Epoch 274/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0213\n",
      "Epoch 275/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0150\n",
      "Epoch 276/1000\n",
      "26/26 [==============================] - 0s 518us/step - loss: 0.0164\n",
      "Epoch 277/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0187\n",
      "Epoch 278/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0070\n",
      "Epoch 279/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0140\n",
      "Epoch 280/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0184\n",
      "Epoch 281/1000\n",
      "26/26 [==============================] - 0s 565us/step - loss: 0.0563\n",
      "Epoch 282/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0115\n",
      "Epoch 283/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0170\n",
      "Epoch 284/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0104\n",
      "Epoch 285/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0333\n",
      "Epoch 286/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0089\n",
      "Epoch 287/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0228\n",
      "Epoch 288/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0400\n",
      "Epoch 289/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0203\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 519us/step - loss: 0.0113\n",
      "Epoch 291/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0128\n",
      "Epoch 292/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0320\n",
      "Epoch 293/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0134\n",
      "Epoch 294/1000\n",
      "26/26 [==============================] - 0s 506us/step - loss: 0.0129\n",
      "Epoch 295/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0235\n",
      "Epoch 296/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0161\n",
      "Epoch 297/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0405\n",
      "Epoch 298/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0042\n",
      "Epoch 299/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0073\n",
      "Epoch 300/1000\n",
      "26/26 [==============================] - 0s 517us/step - loss: 0.0276\n",
      "Epoch 301/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0540\n",
      "Epoch 302/1000\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.0237\n",
      "Epoch 303/1000\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.0134\n",
      "Epoch 304/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0106\n",
      "Epoch 305/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0079\n",
      "Epoch 306/1000\n",
      "26/26 [==============================] - 0s 599us/step - loss: 0.0147\n",
      "Epoch 307/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0304\n",
      "Epoch 308/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0205\n",
      "Epoch 309/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0086\n",
      "Epoch 310/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0227\n",
      "Epoch 311/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0119\n",
      "Epoch 312/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0111\n",
      "Epoch 313/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0150\n",
      "Epoch 314/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0088\n",
      "Epoch 315/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0107\n",
      "Epoch 316/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0089\n",
      "Epoch 317/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0208\n",
      "Epoch 318/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0147\n",
      "Epoch 319/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0175\n",
      "Epoch 320/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0156\n",
      "Epoch 321/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0204\n",
      "Epoch 322/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0098\n",
      "Epoch 323/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0185\n",
      "Epoch 324/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0217\n",
      "Epoch 325/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0190\n",
      "Epoch 326/1000\n",
      "26/26 [==============================] - 0s 478us/step - loss: 0.0625\n",
      "Epoch 327/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0157\n",
      "Epoch 328/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0109\n",
      "Epoch 329/1000\n",
      "26/26 [==============================] - 0s 918us/step - loss: 0.3564\n",
      "Epoch 330/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0048\n",
      "Epoch 331/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0196\n",
      "Epoch 332/1000\n",
      "26/26 [==============================] - 0s 518us/step - loss: 0.0148\n",
      "Epoch 333/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0188\n",
      "Epoch 334/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0244\n",
      "Epoch 335/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0352\n",
      "Epoch 336/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0106\n",
      "Epoch 337/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0056\n",
      "Epoch 338/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0060\n",
      "Epoch 339/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0063\n",
      "Epoch 340/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0692\n",
      "Epoch 341/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0314\n",
      "Epoch 342/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0176\n",
      "Epoch 343/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0169\n",
      "Epoch 344/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0061\n",
      "Epoch 345/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0071\n",
      "Epoch 346/1000\n",
      "26/26 [==============================] - 0s 560us/step - loss: 0.0035\n",
      "Epoch 347/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0448\n",
      "Epoch 348/1000\n",
      "26/26 [==============================] - 0s 600us/step - loss: 0.0041\n",
      "Epoch 349/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0056\n",
      "Epoch 350/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0091\n",
      "Epoch 351/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0138\n",
      "Epoch 352/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0037\n",
      "Epoch 353/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0272\n",
      "Epoch 354/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0125\n",
      "Epoch 355/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0075\n",
      "Epoch 356/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0409\n",
      "Epoch 357/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0136\n",
      "Epoch 358/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0074\n",
      "Epoch 359/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0097\n",
      "Epoch 360/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0068\n",
      "Epoch 361/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0061\n",
      "Epoch 362/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0164\n",
      "Epoch 363/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0058\n",
      "Epoch 364/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0084\n",
      "Epoch 365/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0204\n",
      "Epoch 366/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0103\n",
      "Epoch 367/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0149\n",
      "Epoch 368/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0167\n",
      "Epoch 369/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0082\n",
      "Epoch 370/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0141\n",
      "Epoch 371/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0037\n",
      "Epoch 372/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0103\n",
      "Epoch 373/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0060\n",
      "Epoch 374/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0733\n",
      "Epoch 375/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0158\n",
      "Epoch 376/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0053\n",
      "Epoch 377/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0044\n",
      "Epoch 378/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0117\n",
      "Epoch 379/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0058\n",
      "Epoch 380/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0078\n",
      "Epoch 381/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0069\n",
      "Epoch 382/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0039\n",
      "Epoch 383/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0179\n",
      "Epoch 384/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0140\n",
      "Epoch 385/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0111\n",
      "Epoch 386/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 479us/step - loss: 0.0336\n",
      "Epoch 387/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0026\n",
      "Epoch 388/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0069\n",
      "Epoch 389/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0170\n",
      "Epoch 390/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0151\n",
      "Epoch 391/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0037\n",
      "Epoch 392/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0069\n",
      "Epoch 393/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0216\n",
      "Epoch 394/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0075\n",
      "Epoch 395/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0072\n",
      "Epoch 396/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0207\n",
      "Epoch 397/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0192\n",
      "Epoch 398/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0064\n",
      "Epoch 399/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0171\n",
      "Epoch 400/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0060\n",
      "Epoch 401/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0083\n",
      "Epoch 402/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0088\n",
      "Epoch 403/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.1827\n",
      "Epoch 404/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0233\n",
      "Epoch 405/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0065\n",
      "Epoch 406/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0074\n",
      "Epoch 407/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0052\n",
      "Epoch 408/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0040\n",
      "Epoch 409/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0111\n",
      "Epoch 410/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0293\n",
      "Epoch 411/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0154\n",
      "Epoch 412/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0084\n",
      "Epoch 413/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0131\n",
      "Epoch 414/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0143\n",
      "Epoch 415/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0115\n",
      "Epoch 416/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0140\n",
      "Epoch 417/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0150\n",
      "Epoch 418/1000\n",
      "26/26 [==============================] - 0s 798us/step - loss: 0.0055\n",
      "Epoch 419/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0120\n",
      "Epoch 420/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0076\n",
      "Epoch 421/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0075\n",
      "Epoch 422/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0057\n",
      "Epoch 423/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0059\n",
      "Epoch 424/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0072\n",
      "Epoch 425/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0219\n",
      "Epoch 426/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0145\n",
      "Epoch 427/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0084\n",
      "Epoch 428/1000\n",
      "26/26 [==============================] - 0s 525us/step - loss: 0.0019\n",
      "Epoch 429/1000\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.0028\n",
      "Epoch 430/1000\n",
      "26/26 [==============================] - 0s 762us/step - loss: 0.0088\n",
      "Epoch 431/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0064\n",
      "Epoch 432/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0531\n",
      "Epoch 433/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0031\n",
      "Epoch 434/1000\n",
      "26/26 [==============================] - 0s 524us/step - loss: 0.0114\n",
      "Epoch 435/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0110\n",
      "Epoch 436/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0065\n",
      "Epoch 437/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0047\n",
      "Epoch 438/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0045\n",
      "Epoch 439/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0255\n",
      "Epoch 440/1000\n",
      "26/26 [==============================] - 0s 517us/step - loss: 0.0035\n",
      "Epoch 441/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0019\n",
      "Epoch 442/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0144\n",
      "Epoch 443/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0123\n",
      "Epoch 444/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0079\n",
      "Epoch 445/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0247\n",
      "Epoch 446/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0034\n",
      "Epoch 447/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0115\n",
      "Epoch 448/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0035\n",
      "Epoch 449/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0064\n",
      "Epoch 450/1000\n",
      "26/26 [==============================] - 0s 639us/step - loss: 0.0048\n",
      "Epoch 451/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0137\n",
      "Epoch 452/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0206\n",
      "Epoch 453/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0041\n",
      "Epoch 454/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0128\n",
      "Epoch 455/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0080\n",
      "Epoch 456/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0088\n",
      "Epoch 457/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0162\n",
      "Epoch 458/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0062\n",
      "Epoch 459/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0146\n",
      "Epoch 460/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0133\n",
      "Epoch 461/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0075\n",
      "Epoch 462/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0144\n",
      "Epoch 463/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0265\n",
      "Epoch 464/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0076\n",
      "Epoch 465/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0186\n",
      "Epoch 466/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0107\n",
      "Epoch 467/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0059\n",
      "Epoch 468/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0064\n",
      "Epoch 469/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0022\n",
      "Epoch 470/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0065\n",
      "Epoch 471/1000\n",
      "26/26 [==============================] - 0s 560us/step - loss: 0.0036\n",
      "Epoch 472/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0065\n",
      "Epoch 473/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0240\n",
      "Epoch 474/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0139\n",
      "Epoch 475/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0089\n",
      "Epoch 476/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0066\n",
      "Epoch 477/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0090\n",
      "Epoch 478/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0046\n",
      "Epoch 479/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0080\n",
      "Epoch 480/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0044\n",
      "Epoch 481/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0063\n",
      "Epoch 482/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 479us/step - loss: 0.0093\n",
      "Epoch 483/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0080\n",
      "Epoch 484/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0076\n",
      "Epoch 485/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0042\n",
      "Epoch 486/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0042\n",
      "Epoch 487/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0089\n",
      "Epoch 488/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0040\n",
      "Epoch 489/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0148\n",
      "Epoch 490/1000\n",
      "26/26 [==============================] - 0s 600us/step - loss: 0.0100\n",
      "Epoch 491/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0087\n",
      "Epoch 492/1000\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.0041\n",
      "Epoch 493/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0330\n",
      "Epoch 494/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0054\n",
      "Epoch 495/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0076\n",
      "Epoch 496/1000\n",
      "26/26 [==============================] - 0s 798us/step - loss: 0.0052\n",
      "Epoch 497/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0044\n",
      "Epoch 498/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0120\n",
      "Epoch 499/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0231\n",
      "Epoch 500/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0097\n",
      "Epoch 501/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0073\n",
      "Epoch 502/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0087\n",
      "Epoch 503/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0068\n",
      "Epoch 504/1000\n",
      "26/26 [==============================] - 0s 486us/step - loss: 0.0073\n",
      "Epoch 505/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0041\n",
      "Epoch 506/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0135\n",
      "Epoch 507/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0155\n",
      "Epoch 508/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0196\n",
      "Epoch 509/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0227\n",
      "Epoch 510/1000\n",
      "26/26 [==============================] - 0s 399us/step - loss: 0.0172\n",
      "Epoch 511/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0106\n",
      "Epoch 512/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0095\n",
      "Epoch 513/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0100\n",
      "Epoch 514/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0043\n",
      "Epoch 515/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0113\n",
      "Epoch 516/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0083\n",
      "Epoch 517/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0060\n",
      "Epoch 518/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0046\n",
      "Epoch 519/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0174\n",
      "Epoch 520/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0055\n",
      "Epoch 521/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0101\n",
      "Epoch 522/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0101\n",
      "Epoch 523/1000\n",
      "26/26 [==============================] - 0s 640us/step - loss: 0.0089\n",
      "Epoch 524/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0074\n",
      "Epoch 525/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0124\n",
      "Epoch 526/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0086\n",
      "Epoch 527/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0190\n",
      "Epoch 528/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0023\n",
      "Epoch 529/1000\n",
      "26/26 [==============================] - 0s 852us/step - loss: 0.0769\n",
      "Epoch 530/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0057\n",
      "Epoch 531/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0035\n",
      "Epoch 532/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0015\n",
      "Epoch 533/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0020\n",
      "Epoch 534/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0039\n",
      "Epoch 535/1000\n",
      "26/26 [==============================] - 0s 566us/step - loss: 0.0495\n",
      "Epoch 536/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0100\n",
      "Epoch 537/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0065\n",
      "Epoch 538/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0035\n",
      "Epoch 539/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0030\n",
      "Epoch 540/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0071\n",
      "Epoch 541/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0024\n",
      "Epoch 542/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0064\n",
      "Epoch 543/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0235\n",
      "Epoch 544/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0118\n",
      "Epoch 545/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0163\n",
      "Epoch 546/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0101\n",
      "Epoch 547/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0014\n",
      "Epoch 548/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0071\n",
      "Epoch 549/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0036\n",
      "Epoch 550/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0034\n",
      "Epoch 551/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0051\n",
      "Epoch 552/1000\n",
      "26/26 [==============================] - 0s 798us/step - loss: 0.0384\n",
      "Epoch 553/1000\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.0053\n",
      "Epoch 554/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0058\n",
      "Epoch 555/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0048\n",
      "Epoch 556/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0056\n",
      "Epoch 557/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0094\n",
      "Epoch 558/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0079\n",
      "Epoch 559/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0061\n",
      "Epoch 560/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0054\n",
      "Epoch 561/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0055\n",
      "Epoch 562/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0012\n",
      "Epoch 563/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0014\n",
      "Epoch 564/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0012\n",
      "Epoch 565/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0034\n",
      "Epoch 566/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0271\n",
      "Epoch 567/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0080\n",
      "Epoch 568/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0029\n",
      "Epoch 569/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0036\n",
      "Epoch 570/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0020\n",
      "Epoch 571/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0030\n",
      "Epoch 572/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0026\n",
      "Epoch 573/1000\n",
      "26/26 [==============================] - 0s 798us/step - loss: 0.0026\n",
      "Epoch 574/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0026\n",
      "Epoch 575/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0018\n",
      "Epoch 576/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0073\n",
      "Epoch 577/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0056\n",
      "Epoch 578/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 598us/step - loss: 0.0034\n",
      "Epoch 579/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0066\n",
      "Epoch 580/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0030\n",
      "Epoch 581/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0013\n",
      "Epoch 582/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0143\n",
      "Epoch 583/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0125\n",
      "Epoch 584/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0011\n",
      "Epoch 585/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 6.8580e-04\n",
      "Epoch 586/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0011\n",
      "Epoch 587/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0050\n",
      "Epoch 588/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0030\n",
      "Epoch 589/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0027\n",
      "Epoch 590/1000\n",
      "26/26 [==============================] - 0s 599us/step - loss: 0.0010\n",
      "Epoch 591/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0055\n",
      "Epoch 592/1000\n",
      "26/26 [==============================] - 0s 560us/step - loss: 0.0035\n",
      "Epoch 593/1000\n",
      "26/26 [==============================] - 0s 622us/step - loss: 0.0079\n",
      "Epoch 594/1000\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.0024\n",
      "Epoch 595/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0026\n",
      "Epoch 596/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0045\n",
      "Epoch 597/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0416\n",
      "Epoch 598/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0019\n",
      "Epoch 599/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0015\n",
      "Epoch 600/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0069\n",
      "Epoch 601/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0071\n",
      "Epoch 602/1000\n",
      "26/26 [==============================] - 0s 599us/step - loss: 0.0027\n",
      "Epoch 603/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0031\n",
      "Epoch 604/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0019\n",
      "Epoch 605/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0029\n",
      "Epoch 606/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0108\n",
      "Epoch 607/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0097\n",
      "Epoch 608/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0044\n",
      "Epoch 609/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0021\n",
      "Epoch 610/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0070\n",
      "Epoch 611/1000\n",
      "26/26 [==============================] - 0s 757us/step - loss: 0.0070\n",
      "Epoch 612/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0066\n",
      "Epoch 613/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0031\n",
      "Epoch 614/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0018\n",
      "Epoch 615/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0018\n",
      "Epoch 616/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0017\n",
      "Epoch 617/1000\n",
      "26/26 [==============================] - 0s 550us/step - loss: 0.0068\n",
      "Epoch 618/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0025\n",
      "Epoch 619/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0145\n",
      "Epoch 620/1000\n",
      "26/26 [==============================] - 0s 557us/step - loss: 0.0016\n",
      "Epoch 621/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0012\n",
      "Epoch 622/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0049\n",
      "Epoch 623/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0035\n",
      "Epoch 624/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0029\n",
      "Epoch 625/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0017\n",
      "Epoch 626/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0121\n",
      "Epoch 627/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0021\n",
      "Epoch 628/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0058\n",
      "Epoch 629/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0079\n",
      "Epoch 630/1000\n",
      "26/26 [==============================] - 0s 459us/step - loss: 0.0054\n",
      "Epoch 631/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0022\n",
      "Epoch 632/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 5.6808e-04\n",
      "Epoch 633/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0046\n",
      "Epoch 634/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0016\n",
      "Epoch 635/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0012\n",
      "Epoch 636/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0019\n",
      "Epoch 637/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0033\n",
      "Epoch 638/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0039\n",
      "Epoch 639/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0047\n",
      "Epoch 640/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0043\n",
      "Epoch 641/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0066\n",
      "Epoch 642/1000\n",
      "26/26 [==============================] - 0s 518us/step - loss: 0.0045\n",
      "Epoch 643/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0014\n",
      "Epoch 644/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0018\n",
      "Epoch 645/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0012\n",
      "Epoch 646/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0046\n",
      "Epoch 647/1000\n",
      "26/26 [==============================] - 0s 521us/step - loss: 0.0052\n",
      "Epoch 648/1000\n",
      "26/26 [==============================] - 0s 758us/step - loss: 0.0238\n",
      "Epoch 649/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0033\n",
      "Epoch 650/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0051\n",
      "Epoch 651/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0013\n",
      "Epoch 652/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0042\n",
      "Epoch 653/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 8.2095e-04\n",
      "Epoch 654/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0024\n",
      "Epoch 655/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0047\n",
      "Epoch 656/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0025\n",
      "Epoch 657/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0011\n",
      "Epoch 658/1000\n",
      "26/26 [==============================] - 0s 600us/step - loss: 0.0020\n",
      "Epoch 659/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0013\n",
      "Epoch 660/1000\n",
      "26/26 [==============================] - 0s 518us/step - loss: 0.0055\n",
      "Epoch 661/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0024\n",
      "Epoch 662/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0123\n",
      "Epoch 663/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0053\n",
      "Epoch 664/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0045\n",
      "Epoch 665/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0045\n",
      "Epoch 666/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0031\n",
      "Epoch 667/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0016\n",
      "Epoch 668/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0014\n",
      "Epoch 669/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0223\n",
      "Epoch 670/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0023\n",
      "Epoch 671/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0041\n",
      "Epoch 672/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0012\n",
      "Epoch 673/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0024\n",
      "Epoch 674/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 598us/step - loss: 0.0039\n",
      "Epoch 675/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0057\n",
      "Epoch 676/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 7.5495e-04\n",
      "Epoch 677/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0037\n",
      "Epoch 678/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 9.0097e-04\n",
      "Epoch 679/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0463\n",
      "Epoch 680/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0021\n",
      "Epoch 681/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0038\n",
      "Epoch 682/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0014\n",
      "Epoch 683/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0027\n",
      "Epoch 684/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0023\n",
      "Epoch 685/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0018\n",
      "Epoch 686/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0031\n",
      "Epoch 687/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0016\n",
      "Epoch 688/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0027\n",
      "Epoch 689/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0100\n",
      "Epoch 690/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0892\n",
      "Epoch 691/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0012\n",
      "Epoch 692/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0031\n",
      "Epoch 693/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0027\n",
      "Epoch 694/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 9.6944e-04\n",
      "Epoch 695/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0048\n",
      "Epoch 696/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0064\n",
      "Epoch 697/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0012\n",
      "Epoch 698/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0017\n",
      "Epoch 699/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0014\n",
      "Epoch 700/1000\n",
      "26/26 [==============================] - 0s 661us/step - loss: 0.0014\n",
      "Epoch 701/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0916\n",
      "Epoch 702/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 8.5919e-04\n",
      "Epoch 703/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0051\n",
      "Epoch 704/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 6.2193e-04\n",
      "Epoch 705/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0014\n",
      "Epoch 706/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 9.0650e-04\n",
      "Epoch 707/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0016\n",
      "Epoch 708/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0049\n",
      "Epoch 709/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0026\n",
      "Epoch 710/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0033\n",
      "Epoch 711/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0023\n",
      "Epoch 712/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0037\n",
      "Epoch 713/1000\n",
      "26/26 [==============================] - 0s 798us/step - loss: 0.0028\n",
      "Epoch 714/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0018\n",
      "Epoch 715/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0033\n",
      "Epoch 716/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0013\n",
      "Epoch 717/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0055\n",
      "Epoch 718/1000\n",
      "26/26 [==============================] - 0s 878us/step - loss: 9.6620e-04\n",
      "Epoch 719/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0022\n",
      "Epoch 720/1000\n",
      "26/26 [==============================] - 0s 592us/step - loss: 0.0151\n",
      "Epoch 721/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0323\n",
      "Epoch 722/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0042\n",
      "Epoch 723/1000\n",
      "26/26 [==============================] - 0s 499us/step - loss: 0.0019\n",
      "Epoch 724/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0040\n",
      "Epoch 725/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0026\n",
      "Epoch 726/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0016\n",
      "Epoch 727/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0011\n",
      "Epoch 728/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 8.5243e-04\n",
      "Epoch 729/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 7.5169e-04\n",
      "Epoch 730/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0017\n",
      "Epoch 731/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0042\n",
      "Epoch 732/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.2001\n",
      "Epoch 733/1000\n",
      "26/26 [==============================] - 0s 599us/step - loss: 0.0147\n",
      "Epoch 734/1000\n",
      "26/26 [==============================] - 0s 838us/step - loss: 0.0021\n",
      "Epoch 735/1000\n",
      "26/26 [==============================] - 0s 599us/step - loss: 9.0662e-04\n",
      "Epoch 736/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 5.9530e-04\n",
      "Epoch 737/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0037\n",
      "Epoch 738/1000\n",
      "26/26 [==============================] - 0s 718us/step - loss: 5.9121e-04\n",
      "Epoch 739/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 3.6377e-04\n",
      "Epoch 740/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0011\n",
      "Epoch 741/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0034\n",
      "Epoch 742/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0010\n",
      "Epoch 743/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 7.5573e-04\n",
      "Epoch 744/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0011\n",
      "Epoch 745/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 9.1303e-04\n",
      "Epoch 746/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0014\n",
      "Epoch 747/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0026\n",
      "Epoch 748/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0014\n",
      "Epoch 749/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0752\n",
      "Epoch 750/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0031\n",
      "Epoch 751/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0016\n",
      "Epoch 752/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0027\n",
      "Epoch 753/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0022\n",
      "Epoch 754/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0039\n",
      "Epoch 755/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0013\n",
      "Epoch 756/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0018\n",
      "Epoch 757/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0048\n",
      "Epoch 758/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 6.7436e-04\n",
      "Epoch 759/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0017\n",
      "Epoch 760/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0018\n",
      "Epoch 761/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0012\n",
      "Epoch 762/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0016\n",
      "Epoch 763/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0029\n",
      "Epoch 764/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0019\n",
      "Epoch 765/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0039\n",
      "Epoch 766/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0018\n",
      "Epoch 767/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0022\n",
      "Epoch 768/1000\n",
      "26/26 [==============================] - 0s 518us/step - loss: 0.0119\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 598us/step - loss: 0.0034\n",
      "Epoch 770/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0022\n",
      "Epoch 771/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0011\n",
      "Epoch 772/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0012\n",
      "Epoch 773/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 4.8484e-04\n",
      "Epoch 774/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0025\n",
      "Epoch 775/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0029\n",
      "Epoch 776/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0043\n",
      "Epoch 777/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0028\n",
      "Epoch 778/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0019\n",
      "Epoch 779/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 9.4594e-04\n",
      "Epoch 780/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 5.5184e-04\n",
      "Epoch 781/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0013\n",
      "Epoch 782/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 6.7532e-04\n",
      "Epoch 783/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0022\n",
      "Epoch 784/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0034\n",
      "Epoch 785/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0025\n",
      "Epoch 786/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0116\n",
      "Epoch 787/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0026\n",
      "Epoch 788/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 6.9002e-04\n",
      "Epoch 789/1000\n",
      "26/26 [==============================] - 0s 624us/step - loss: 0.0020\n",
      "Epoch 790/1000\n",
      "26/26 [==============================] - 0s 500us/step - loss: 9.3587e-04\n",
      "Epoch 791/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0049\n",
      "Epoch 792/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 4.7971e-04\n",
      "Epoch 793/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 2.1686e-04\n",
      "Epoch 794/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0024\n",
      "Epoch 795/1000\n",
      "26/26 [==============================] - 0s 663us/step - loss: 0.0010\n",
      "Epoch 796/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0021\n",
      "Epoch 797/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0029\n",
      "Epoch 798/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0056\n",
      "Epoch 799/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 5.4316e-04\n",
      "Epoch 800/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0016\n",
      "Epoch 801/1000\n",
      "26/26 [==============================] - 0s 758us/step - loss: 0.0034\n",
      "Epoch 802/1000\n",
      "26/26 [==============================] - 0s 599us/step - loss: 4.0961e-04\n",
      "Epoch 803/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 6.7364e-04\n",
      "Epoch 804/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 8.9861e-04\n",
      "Epoch 805/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0017\n",
      "Epoch 806/1000\n",
      "26/26 [==============================] - 0s 599us/step - loss: 0.0011\n",
      "Epoch 807/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 4.0751e-04\n",
      "Epoch 808/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0010\n",
      "Epoch 809/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0020\n",
      "Epoch 810/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0032\n",
      "Epoch 811/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 5.7342e-04\n",
      "Epoch 812/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0197\n",
      "Epoch 813/1000\n",
      "26/26 [==============================] - 0s 758us/step - loss: 8.6556e-04\n",
      "Epoch 814/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0019\n",
      "Epoch 815/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 8.3366e-04\n",
      "Epoch 816/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 8.5447e-04\n",
      "Epoch 817/1000\n",
      "26/26 [==============================] - 0s 620us/step - loss: 6.3319e-04\n",
      "Epoch 818/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 8.4086e-04\n",
      "Epoch 819/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0024\n",
      "Epoch 820/1000\n",
      "26/26 [==============================] - ETA: 0s - loss: 1.4965e-1 - 0s 479us/step - loss: 0.0014\n",
      "Epoch 821/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 9.6052e-04\n",
      "Epoch 822/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0024\n",
      "Epoch 823/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0011\n",
      "Epoch 824/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0028\n",
      "Epoch 825/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 2.4608e-04\n",
      "Epoch 826/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0053\n",
      "Epoch 827/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 9.1028e-04\n",
      "Epoch 828/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0031\n",
      "Epoch 829/1000\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.0015\n",
      "Epoch 830/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0032\n",
      "Epoch 831/1000\n",
      "26/26 [==============================] - 0s 798us/step - loss: 3.7419e-04\n",
      "Epoch 832/1000\n",
      "26/26 [==============================] - 0s 718us/step - loss: 0.0029\n",
      "Epoch 833/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 6.4124e-04\n",
      "Epoch 834/1000\n",
      "26/26 [==============================] - 0s 599us/step - loss: 0.0027\n",
      "Epoch 835/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0019\n",
      "Epoch 836/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0015\n",
      "Epoch 837/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 8.6471e-04\n",
      "Epoch 838/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0017\n",
      "Epoch 839/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 9.9207e-04\n",
      "Epoch 840/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 4.0978e-04\n",
      "Epoch 841/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0013\n",
      "Epoch 842/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0012\n",
      "Epoch 843/1000\n",
      "26/26 [==============================] - ETA: 0s - loss: 3.9268e-2 - 0s 598us/step - loss: 0.0359\n",
      "Epoch 844/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0016\n",
      "Epoch 845/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 2.5686e-04\n",
      "Epoch 846/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0028\n",
      "Epoch 847/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 6.6455e-04\n",
      "Epoch 848/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0014\n",
      "Epoch 849/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0020\n",
      "Epoch 850/1000\n",
      "26/26 [==============================] - 0s 758us/step - loss: 6.2254e-04\n",
      "Epoch 851/1000\n",
      "26/26 [==============================] - 0s 838us/step - loss: 2.4901e-04\n",
      "Epoch 852/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 4.8271e-04\n",
      "Epoch 853/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0109\n",
      "Epoch 854/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0016\n",
      "Epoch 855/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0019\n",
      "Epoch 856/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 9.0024e-04\n",
      "Epoch 857/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 3.2600e-04\n",
      "Epoch 858/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1.6234e-04\n",
      "Epoch 859/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 6.3151e-04\n",
      "Epoch 860/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 6.7839e-04\n",
      "Epoch 861/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 6.6596e-04\n",
      "Epoch 862/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 3.4231e-04\n",
      "Epoch 863/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 519us/step - loss: 8.4929e-04\n",
      "Epoch 864/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0011\n",
      "Epoch 865/1000\n",
      "26/26 [==============================] - ETA: 0s - loss: 8.3434e-2 - 0s 598us/step - loss: 3.3728e-04\n",
      "Epoch 866/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0017\n",
      "Epoch 867/1000\n",
      "26/26 [==============================] - 0s 599us/step - loss: 8.7185e-04\n",
      "Epoch 868/1000\n",
      "26/26 [==============================] - 0s 557us/step - loss: 9.6662e-04\n",
      "Epoch 869/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 0.0017\n",
      "Epoch 870/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 9.4876e-04\n",
      "Epoch 871/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0012\n",
      "Epoch 872/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 3.5016e-04\n",
      "Epoch 873/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 3.6221e-04\n",
      "Epoch 874/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 1.9696e-04\n",
      "Epoch 875/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 4.5026e-04\n",
      "Epoch 876/1000\n",
      "26/26 [==============================] - 0s 599us/step - loss: 0.0011\n",
      "Epoch 877/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 9.5530e-04\n",
      "Epoch 878/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 2.8861e-04\n",
      "Epoch 879/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0015\n",
      "Epoch 880/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 3.8013e-04\n",
      "Epoch 881/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0097\n",
      "Epoch 882/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0016\n",
      "Epoch 883/1000\n",
      "26/26 [==============================] - 0s 601us/step - loss: 0.0016\n",
      "Epoch 884/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0011\n",
      "Epoch 885/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 4.4623e-04\n",
      "Epoch 886/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 5.8525e-04\n",
      "Epoch 887/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0012\n",
      "Epoch 888/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0012\n",
      "Epoch 889/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0012\n",
      "Epoch 890/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 4.0415e-04\n",
      "Epoch 891/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0023\n",
      "Epoch 892/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 8.1364e-04\n",
      "Epoch 893/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0010\n",
      "Epoch 894/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 9.6098e-04\n",
      "Epoch 895/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0020\n",
      "Epoch 896/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0022\n",
      "Epoch 897/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0015\n",
      "Epoch 898/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0012\n",
      "Epoch 899/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 6.4642e-04\n",
      "Epoch 900/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 7.6231e-04\n",
      "Epoch 901/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 2.2006e-04\n",
      "Epoch 902/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 6.1608e-04\n",
      "Epoch 903/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0023\n",
      "Epoch 904/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 6.2191e-04\n",
      "Epoch 905/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 8.7420e-04\n",
      "Epoch 906/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 7.2843e-04\n",
      "Epoch 907/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0017\n",
      "Epoch 908/1000\n",
      "26/26 [==============================] - 0s 522us/step - loss: 0.0012\n",
      "Epoch 909/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0012\n",
      "Epoch 910/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0018\n",
      "Epoch 911/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0013\n",
      "Epoch 912/1000\n",
      "26/26 [==============================] - 0s 518us/step - loss: 6.3670e-04\n",
      "Epoch 913/1000\n",
      "26/26 [==============================] - 0s 918us/step - loss: 7.1698e-04\n",
      "Epoch 914/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0028\n",
      "Epoch 915/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0013\n",
      "Epoch 916/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 8.8778e-04\n",
      "Epoch 917/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 6.2511e-04\n",
      "Epoch 918/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 7.3192e-04\n",
      "Epoch 919/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0010\n",
      "Epoch 920/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 3.4621e-04\n",
      "Epoch 921/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0015\n",
      "Epoch 922/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 4.4082e-04\n",
      "Epoch 923/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0011\n",
      "Epoch 924/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 9.8121e-04\n",
      "Epoch 925/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 4.8603e-04\n",
      "Epoch 926/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1.9236e-04\n",
      "Epoch 927/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0014\n",
      "Epoch 928/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0016\n",
      "Epoch 929/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0011\n",
      "Epoch 930/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 6.7612e-04\n",
      "Epoch 931/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 5.3797e-04\n",
      "Epoch 932/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0013\n",
      "Epoch 933/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 7.0670e-04\n",
      "Epoch 934/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 6.4099e-04\n",
      "Epoch 935/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 0.0019\n",
      "Epoch 936/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 7.7690e-04\n",
      "Epoch 937/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 7.3783e-04\n",
      "Epoch 938/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0020\n",
      "Epoch 939/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 6.1074e-04\n",
      "Epoch 940/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 2.9857e-04\n",
      "Epoch 941/1000\n",
      "26/26 [==============================] - 0s 599us/step - loss: 2.2380e-04\n",
      "Epoch 942/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0011\n",
      "Epoch 943/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 3.6805e-04\n",
      "Epoch 944/1000\n",
      "26/26 [==============================] - 0s 600us/step - loss: 3.8811e-04\n",
      "Epoch 945/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0012\n",
      "Epoch 946/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0017\n",
      "Epoch 947/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0014\n",
      "Epoch 948/1000\n",
      "26/26 [==============================] - 0s 638us/step - loss: 6.0555e-04\n",
      "Epoch 949/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0015\n",
      "Epoch 950/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0013\n",
      "Epoch 951/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0019\n",
      "Epoch 952/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 7.4686e-04\n",
      "Epoch 953/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 6.9504e-04\n",
      "Epoch 954/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0011\n",
      "Epoch 955/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 5.1702e-04\n",
      "Epoch 956/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 598us/step - loss: 7.0899e-04\n",
      "Epoch 957/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 4.3904e-04\n",
      "Epoch 958/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0043\n",
      "Epoch 959/1000\n",
      "26/26 [==============================] - 0s 557us/step - loss: 0.0016\n",
      "Epoch 960/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 3.8785e-04\n",
      "Epoch 961/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 8.9517e-04\n",
      "Epoch 962/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 3.2344e-04\n",
      "Epoch 963/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0015\n",
      "Epoch 964/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 0.0013\n",
      "Epoch 965/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 5.3785e-04\n",
      "Epoch 966/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 1.9947e-04\n",
      "Epoch 967/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 3.1540e-04\n",
      "Epoch 968/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 4.5964e-04\n",
      "Epoch 969/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 9.3700e-04\n",
      "Epoch 970/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 7.8591e-04\n",
      "Epoch 971/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 7.0607e-04\n",
      "Epoch 972/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 6.5050e-04\n",
      "Epoch 973/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0013\n",
      "Epoch 974/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 4.8414e-04\n",
      "Epoch 975/1000\n",
      "26/26 [==============================] - 0s 878us/step - loss: 0.0014\n",
      "Epoch 976/1000\n",
      "26/26 [==============================] - 0s 678us/step - loss: 0.0018\n",
      "Epoch 977/1000\n",
      "26/26 [==============================] - 0s 579us/step - loss: 6.3899e-04\n",
      "Epoch 978/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 0.0013\n",
      "Epoch 979/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 4.4413e-04\n",
      "Epoch 980/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 0.0029\n",
      "Epoch 981/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0010\n",
      "Epoch 982/1000\n",
      "26/26 [==============================] - 0s 439us/step - loss: 8.9148e-04\n",
      "Epoch 983/1000\n",
      "26/26 [==============================] - 0s 522us/step - loss: 5.8074e-04\n",
      "Epoch 984/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 5.4142e-04\n",
      "Epoch 985/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 2.0880e-04\n",
      "Epoch 986/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 5.2437e-04\n",
      "Epoch 987/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 7.7129e-04\n",
      "Epoch 988/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 1.8833e-04\n",
      "Epoch 989/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 0.0010\n",
      "Epoch 990/1000\n",
      "26/26 [==============================] - 0s 501us/step - loss: 0.0014\n",
      "Epoch 991/1000\n",
      "26/26 [==============================] - 0s 598us/step - loss: 4.6566e-04\n",
      "Epoch 992/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 4.4668e-04\n",
      "Epoch 993/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 5.1458e-04\n",
      "Epoch 994/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 0.0015\n",
      "Epoch 995/1000\n",
      "26/26 [==============================] - 0s 479us/step - loss: 6.9494e-04\n",
      "Epoch 996/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 9.4031e-04\n",
      "Epoch 997/1000\n",
      "26/26 [==============================] - 0s 798us/step - loss: 9.8006e-04\n",
      "Epoch 998/1000\n",
      "26/26 [==============================] - 0s 558us/step - loss: 4.6889e-04\n",
      "Epoch 999/1000\n",
      "26/26 [==============================] - 0s 559us/step - loss: 4.8453e-04\n",
      "Epoch 1000/1000\n",
      "26/26 [==============================] - 0s 519us/step - loss: 2.8456e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1aa10457c10>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_NN = classifier.predict(X_test)\n",
    "y_pred_NN = [ 1 if y>=0.5 else 0 for y in y_pred_NN ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97        63\n",
      "           1       0.98      0.93      0.96        46\n",
      "\n",
      "    accuracy                           0.96       109\n",
      "   macro avg       0.97      0.96      0.96       109\n",
      "weighted avg       0.96      0.96      0.96       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_NN\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "total = 0\n",
    "correct = 0\n",
    "wrong = 0\n",
    "for i,j in y_pred_NN,y_test:\n",
    "  total=total+1\n",
    "  if(i== j):\n",
    "    correct=correct+1\n",
    "  else:\n",
    "    wrong=wrong+1\n",
    "\n",
    "print(\"Total \" + str(total))\n",
    "print(\"Correct \" + str(correct))\n",
    "print(\"Wrong \" + str(wrong))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 109 points : 7\n"
     ]
    }
   ],
   "source": [
    "### Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "y_pred_bayes = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "      % (X_test.shape[0], (y_test != y_pred_bayes).sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_bayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation accuracy scores: [0.98630137 0.93055556 0.91666667 0.95833333 0.91666667]\n",
      "Mean of Cross Validation scores: 0.9417047184170473\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(gnb, X, y, cv=5, scoring= 'accuracy')\n",
    "print('Cross Validation accuracy scores:', scores)\n",
    "print('Mean of Cross Validation scores:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "#how many components to get X of the explained variane\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca=PCA(0.85)\n",
    "pca_dim_reducts = pca.fit_transform(X)\n",
    "pca_regenerations = pca.inverse_transform(pca_dim_reducts)\n",
    "print(pca.explained_variance_.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## PCA tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is given\n",
    "from numpy import array\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# define a matrix\n",
    "#A = array([[1, 2], [3, 4], [5, 6]])\n",
    "#print(A)\n",
    "\n",
    "# create the PCA instance\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "# fit on data\n",
    "pca.fit(X)\n",
    "'''\n",
    "# access values and vectors\n",
    "print(pca.components_)\n",
    "print(pca.explained_variance_)\n",
    "\n",
    "# transform data\n",
    "B = pca.transform(X)\n",
    "print(B)\n",
    "'''\n",
    "print(pca.explained_variance_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2)  # project from 64 to 2 dimensions\n",
    "projected = pca.fit_transform(X)\n",
    "print(X.shape)\n",
    "print(projected.shape)\n",
    "\n",
    "plt.scatter(projected[:, 0], projected[:, 1],\n",
    "            c=y, edgecolor='none', alpha=0.5,)\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(X)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.n_components = 3\n",
    "X_reduced = pca.fit_transform(X)\n",
    "pca.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled = pd.DataFrame(preprocessing.scale(X),columns = df.columns) \n",
    "data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# load dataset\n",
    "\n",
    "# normalize data\n",
    "from sklearn import preprocessing\n",
    "data_scaled = pd.DataFrame(preprocessing.scale(X),columns = X.columns) \n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit_transform(X.T)\n",
    "\n",
    "# Dump components relations with features:\n",
    "df_pca = pd.DataFrame(pca.components_,columns=data_scaled.columns,index = ['PC-1','PC-2','PC-3'])\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(X['Lactate_dehydrogenase'],y)\n",
    "#plt.show()\n",
    "pca_regenerations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X.T)\n",
    "\n",
    "pca.components_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [0, 1]\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-116.23516787837141\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "regr = MLPRegressor(random_state=1, max_iter=1000).fit(X_train, y_train)\n",
    "#regr.predict(X_test[:2])\n",
    "\n",
    "print(regr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-62b808b2e153>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx_trainNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mx_testNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "x_trainNN = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_testNN = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================= Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "ytrain_pred = rf_model.predict_proba(X_train)\n",
    "print('RF train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\n",
    "ytest_pred = rf_model.predict_proba(X_test)\n",
    "print('RF test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "ytrain_pred = rf_model.predict_proba(X_train)\n",
    "\n",
    "#print (clf.predict_proba(y_test))\n",
    "\n",
    "#clf.score(X_train, y_train)\n",
    "#?#how to do regression in non numerical values\n",
    "print(classification_report(y_test, ytrain_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(rf_model, X, y, cv=5, scoring= 'accuracy')\n",
    "print('Cross Validation accuracy scores:', scores)\n",
    "print('Mean of Cross Validation scores:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create -n newenvt anaconda python=3.5\n",
    "activate newenvt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_classifier=LogisticRegression()\n",
    "log_classifier.fit(X_train, y_train)\n",
    "ytrain_pred = log_classifier.predict_proba(X_train)\n",
    "print('Logistic train roc-auc: {}'.format(roc_auc_score(y_train, ytrain_pred[:,1])))\n",
    "ytest_pred = log_classifier.predict_proba(X_test)\n",
    "print('Logistic test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pd.concat([pari , births['age_cat'] ,etni, births['urban']] ,axis = 'columns') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "ohe =  OneHotEncoder(sparse = False)\n",
    "#ohe =  OneHotEncoder() \n",
    "\n",
    "column_trans= make_column_transformer((OneHotEncoder(), ['parity', 'age_cat', 'etnicity', 'urban']), remainder = 'passthrough')\n",
    "X = column_trans.fit_transform(X)\n",
    "X\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(logreg, X, home, cv=5, scoring= 'accuracy')\n",
    "print('mean of Cross Validation scores:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "\n",
    "clf = clf.fit(X_train ,y_train)\n",
    "\n",
    "tree.plot_tree(clf, filled = True, fontsize = 7) \n",
    "\n",
    "#plt.show()\n",
    "\n",
    "print ('train accuracy:', clf.score(X_test, y_test))\n",
    "print ('test accuracy:', clf.score(X_train, y_train))\n",
    "\n",
    "#fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=300)\n",
    "#clf.savefig('Users\\gougo\\Documents\\Twente\\1B\\Data science\\DM\\imagename.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('Logistic Regression accuracy:',LogisticRegression(random_state=0)),\n",
    "    ('Decision Tree accuracy:', tree.DecisionTreeClassifier(max_depth=3, random_state=0)),\n",
    "]\n",
    "\n",
    "# we have already used sklearn.model_selection to train/test split our dataset so we dont need to do it again\n",
    "\n",
    "for name, model in models:\n",
    "        clf = model\n",
    "        clf.fit(X_train, y_train)\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        print(name, accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have awlready inported and used cross_val_score so we dont need to do it again \n",
    "scoresLR = cross_val_score(logreg, X, home, cv=5, scoring= 'accuracy')\n",
    "print('mean of Cross Validation scores:', scoresLR.mean()) \n",
    "\n",
    "scoresDT = cross_val_score(clf, X, home, cv=5, scoring= 'accuracy')\n",
    "print('mean of Decision Tree scores:', scoresDT.mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
